# LLMux v5.0.0 - Docker Compose Configuration
#
# Usage:
#   docker-compose up -d                    # Default start (memory cache)
#   docker-compose --profile redis up -d    # Start with Redis cache
#   docker-compose --profile ollama up -d   # Start with Ollama
#   docker-compose --profile redis --profile ollama up -d  # Both
#
# Environment variables can be overridden via .env file or command line

version: '3.8'

services:
  llmux:
    build:
      context: .
      dockerfile: Dockerfile
    image: llmux:5.0.0
    container_name: ${CONTAINER_NAME:-llmux}
    restart: unless-stopped
    ports:
      - "${PORT:-8765}:8765"
    environment:
      - NODE_ENV=${NODE_ENV:-production}
      - PORT=8765
      - TZ=${TZ:-UTC}
      - OLLAMA_HOST=${OLLAMA_HOST:-http://host.docker.internal:11434}
      - DEFAULT_PROVIDER=${DEFAULT_PROVIDER:-claude}
      - REQUEST_TIMEOUT=${REQUEST_TIMEOUT:-120000}
      - HOME=/root
      # Cache configuration
      - CACHE_BACKEND=${CACHE_BACKEND:-memory}
      - CACHE_TTL=${CACHE_TTL:-3600000}
      - CACHE_MAX_SIZE=${CACHE_MAX_SIZE:-1000}
      - REDIS_URL=${REDIS_URL:-redis://redis:6379}
      # API Key authentication (optional)
      - API_KEY_REQUIRED=${API_KEY_REQUIRED:-false}
      - API_KEY=${API_KEY:-}
      - ADMIN_KEY=${ADMIN_KEY:-}
    depends_on:
      redis:
        condition: service_healthy
        required: false
    volumes:
      # Application code (hot reload for development)
      - ./server.js:/app/server.js:ro
      - ./logs:/app/logs
      - ./data:/app/data
      # CLI Session authentication directories
      - ${CLAUDE_SESSION:-~/.claude}:/root/.claude:ro
      - ${CODEX_SESSION:-~/.codex}:/root/.codex:ro
      - ${GEMINI_SESSION:-~/.gemini}:/root/.gemini:ro
      - ${GCLOUD_CONFIG:-~/.config/gcloud}:/root/.config/gcloud:ro
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8765/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - llmux-network

  # Optional: Redis cache (start with --profile redis)
  redis:
    image: redis:7-alpine
    container_name: llmux-redis
    profiles:
      - redis
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - llmux-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3

  # Optional: Ollama service (start with --profile ollama)
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    profiles:
      - ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - llmux-network
    # GPU support (NVIDIA)
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]

networks:
  llmux-network:
    driver: bridge

volumes:
  ollama_data:
  redis_data:
